{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a7c99d0-edb1-4849-b9d9-75c0e428d8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "\n",
      "targets:  ['class_0' 'class_1' 'class_2']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import statistics \n",
    "\n",
    "wine = datasets.load_wine()\n",
    "print('features: ' + str(wine.feature_names) + '\\n')\n",
    "print('targets:  ' + str(wine.target_names) + '\\n')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.3) # 70% training and 30% test\n",
    "t_samples, t_features = X_train.shape\n",
    "t_labels = wine.target_names\n",
    "num_labels = len(t_labels)\n",
    "root=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dab0f361-8e74-4682-8fb3-1db078947bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#node class\n",
    "class Node:\n",
    "    def __init__(self, feature=None, threshhold=None, left=None, right=None, value=None):\n",
    "        self.feature = feature\n",
    "        self.thresh = threshhold\n",
    "        self.left=left\n",
    "        self.right=right\n",
    "        self.value=value\n",
    "\n",
    "    def isLeaf(self):\n",
    "        if self.value != None: return True\n",
    "        else :\n",
    "            return False\n",
    "        \n",
    "def fit_tree(X, y):\n",
    "    root = build_tree(X,y)\n",
    "    return root\n",
    "\n",
    "def build_tree(X,y, depth=0):\n",
    "    num_samples, num_features = X.shape\n",
    "    num_labels = len(np.unique(y))\n",
    "\n",
    "    #stopping criteria\n",
    "    if(depth >= max_depth or num_samples<min_samples or num_labels==1):\n",
    "        leaf = statistics.mode(y)\n",
    "        return Node(value=leaf)\n",
    "\n",
    "    #find best split\n",
    "    best_feat, best_thresh = best_split(X, y, num_features)\n",
    "\n",
    "    #create child nodes and recurse\n",
    "    l_idxs, r_idxs = split(X[:,best_feat], best_thresh)\n",
    "    left = build_tree(X[l_idxs,:], y[l_idxs], depth+1)\n",
    "    right = build_tree(X[r_idxs,:], y[r_idxs], depth+1)\n",
    "    return Node(feature=best_feat,threshhold=best_thresh,left=left,right=right)\n",
    "\n",
    "#find split with highest info gain\n",
    "def best_split(X, y, num_features):\n",
    "    best_ig=-1\n",
    "    s_feat_index=None\n",
    "    s_thresh=None\n",
    "    for f in range(num_features):\n",
    "        x_col = X[:,f]\n",
    "        threshs = np.unique(x_col)\n",
    "        for t in threshs:\n",
    "            ig = info_gain(x_col, y, t)\n",
    "            if ig > best_ig:\n",
    "                best_ig=ig\n",
    "                s_feat_index = f\n",
    "                s_thresh = t\n",
    "    return s_feat_index, s_thresh\n",
    "\n",
    "def info_gain(x_col, y, thresh):\n",
    "    #parent entropy\n",
    "    p_entr = entropy(y)\n",
    "\n",
    "    #create children\n",
    "    l_idxs, r_idxs = split(x_col, thresh)\n",
    "    if (len(l_idxs) == 0 or len(r_idxs) == 0): #if left or right side is empty\n",
    "        return 0\n",
    "    \n",
    "    #children entropy\n",
    "    r_entr = entropy(y[r_idxs])\n",
    "    l_entr = entropy(y[l_idxs])\n",
    "\n",
    "    #weighted average * child entropy\n",
    "    num_y = len(y)\n",
    "    w_avg_entr = (len(l_idxs)/num_y) * l_entr + (len(r_idxs)/num_y) * r_entr\n",
    "\n",
    "    #calc info gain\n",
    "    ig = p_entr - w_avg_entr\n",
    "    return ig\n",
    "\n",
    "#-sum(p(X)*log2(p(X))\n",
    "def entropy(y):\n",
    "    count = np.bincount(y)\n",
    "    probability = count/len(y)\n",
    "    sum = 0\n",
    "    for p in probability:\n",
    "        if p > 0:\n",
    "            sum += p*np.log(p)\n",
    "    sum *= -1\n",
    "    return sum\n",
    "\n",
    "#get left and right split indexes\n",
    "def split(x_col, thresh):\n",
    "    left_indexes = np.argwhere(x_col <= thresh).flatten()\n",
    "    right_indexes = np.argwhere(x_col > thresh).flatten()\n",
    "    return (left_indexes, right_indexes)\n",
    "\n",
    "def predict(X_test):\n",
    "    predictions = []\n",
    "    for x in X_test:\n",
    "        p = traverse_tree(x, root)\n",
    "        predictions.append(p)\n",
    "    return predictions\n",
    "\n",
    "def traverse_tree(x, root):\n",
    "    if (root.isLeaf()):\n",
    "        return root.value\n",
    "    \n",
    "    if (x[root.feature] <= root.thresh):\n",
    "        return traverse_tree(x, root.left)\n",
    "    else:\n",
    "        return traverse_tree(x, root.right)\n",
    "    \n",
    "def accuracy(pred, actual):\n",
    "    return(np.sum(pred==actual)/(actual.__len__()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11fbcacc-eeee-4007-af05-881bc09fe695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**SCRATCH DECISION TREE**\n",
      "\n",
      "Scratch Test Accuracy: \n",
      "0.8703703703703703\n",
      "Scratch Train Accuracy: \n",
      "0.9838709677419355\n",
      "\n",
      "\n",
      "**SKLEARN DECISION TREE**\n",
      "\n",
      "Sklearn Test Accuracy:\n",
      "0.8333333333333334\n",
      "Sklearn Train Accuracy:\n",
      "0.9435483870967742\n"
     ]
    }
   ],
   "source": [
    "max_depth = 5\n",
    "min_samples = 5\n",
    "\n",
    "root = fit_tree(X_train, y_train)\n",
    "pred=predict(X_test)\n",
    "\n",
    "print('**SCRATCH DECISION TREE**\\n')\n",
    "print('Scratch Test Accuracy: ')\n",
    "print(accuracy(pred, y_test))\n",
    "pred=predict(X_train)\n",
    "print('Scratch Train Accuracy: ')\n",
    "print(accuracy(pred, y_train))\n",
    "\n",
    "## **Sklearn Implementation**\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "\n",
    "clf_model = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_leaf=5, random_state=42)   \n",
    "clf_model.fit(X_train,y_train)\n",
    "\n",
    "y_predict = clf_model.predict(X_test)\n",
    "y_predict_train = clf_model.predict(X_train)\n",
    "\n",
    "print('\\n\\n**SKLEARN DECISION TREE**\\n')\n",
    "print('Sklearn Test Accuracy:')\n",
    "print(accuracy_score(y_test,y_predict))\n",
    "print('Sklearn Train Accuracy:')\n",
    "print(accuracy_score(y_train,y_predict_train))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
