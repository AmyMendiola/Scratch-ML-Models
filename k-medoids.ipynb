{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52dbfbd9-ca62-4572-a754-73147d2eeaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: ['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7']\n",
      "\n",
      "targets:  [0 1 2 3 4 5 6 7 8 9]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Import scikit-learn dataset library\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "#Load dataset\n",
    "digits = datasets.load_digits()\n",
    "print('features: ' + str(digits.feature_names) + '\\n')\n",
    "print('targets:  ' + str(digits.target_names) + '\\n')\n",
    "X_train = digits.data\n",
    "y_train = digits.target\n",
    "train_num_samples, train_num_features = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4d06616-e027-4769-b334-9f7a33599a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(k, iters):\n",
    "    #init\n",
    "    clusters = []\n",
    "    loss_arr = []\n",
    "    for _ in range(k):\n",
    "        clusters.append([])\n",
    "    #pick a random k points to be the means\n",
    "    cluster_means_idx = get_random_means(k)\n",
    "    cluster_means = []\n",
    "    for _ in cluster_means_idx:\n",
    "        cluster_means.append(X_train[_])\n",
    "\n",
    "    #run optimization n times\n",
    "    for _ in range(iters):\n",
    "        #assign points to clusters\n",
    "        clusters = assign_clusters(k,cluster_means) #good\n",
    "        #set the new means\n",
    "        cluster_means = assign_means(clusters, k)\n",
    "        #print(cluster_means)\n",
    "        if (_%2 == 0): #every 2 iterations calculate the loss\n",
    "            loss_arr.append(k_loss(labels(clusters), cluster_means))\n",
    "\n",
    "    return labels(clusters), cluster_means, loss_arr\n",
    "    \n",
    "\n",
    "def assign_means(clusters, k):\n",
    "    #reset means\n",
    "    cluster_means = np.zeros((k,train_num_features))\n",
    "    #for each cluster\n",
    "    for idx, c in enumerate(clusters):\n",
    "        distances = []\n",
    "        for point in c: #get distances between every point in cluster\n",
    "            distances.append(distance(point,c))\n",
    "        d_sums = []\n",
    "        for d in range(len(distances)): #sum all distances per point\n",
    "            d_sum = sum(distances[d])\n",
    "            d_sums.append(d_sum)\n",
    "        cluster_means[idx]=X_train[c[np.argmin(d_sums)]] #smalles distance is the new mean point\n",
    "    return cluster_means\n",
    "\n",
    "def get_random_means(k):\n",
    "    rand_means = []\n",
    "    rand_means = np.random.choice(train_num_samples, k , False)\n",
    "    return rand_means\n",
    "\n",
    "def distance(x, means):\n",
    "    dist = []\n",
    "    for m in means:\n",
    "        dist.append(np.sqrt(np.sum((x-m)**2)))\n",
    "    return dist\n",
    "\n",
    "def assign_clusters(k, means):\n",
    "    #clear clusters\n",
    "    clusters = []\n",
    "    for _ in range(k):\n",
    "        clusters.append([])\n",
    "\n",
    "    #for each point assign closest mean\n",
    "    for idx, point in enumerate(X_train):\n",
    "        distances = [distance(point, means)]\n",
    "        closest_mean_idx = np.argmin(distances)\n",
    "        clusters[closest_mean_idx].append(idx)\n",
    "    return (clusters)\n",
    "\n",
    "def accuracy(predictions,y,k):\n",
    "    counter = 0\n",
    "    count_arr = np.zeros((k,k))\n",
    "    for _ in range(train_num_samples):\n",
    "        count_arr[y[_],predictions[_]] +=1\n",
    "\n",
    "    return count_arr\n",
    "\n",
    "def labels(clusters):\n",
    "    labels = [None] * train_num_samples\n",
    "    for c_idx, c in enumerate(clusters):\n",
    "        for point_idx in c:\n",
    "            labels[point_idx] = c_idx\n",
    "    return labels\n",
    "\n",
    "def k_loss(y_pred, means):\n",
    "    loss = 0\n",
    "    for idx in range(train_num_samples):\n",
    "        mean = means[y_pred[idx]]\n",
    "        loss+= np.sum((X_train[idx] - mean)**2)\n",
    "    return(loss/train_num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cea93e01-bea4-4ce4-9e2f-f374ac72016d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target value number (rows) by prediction number(columns):\n",
      "[[  0.   0.   0.   0.   1.   0.   0.   0.   0. 177.]\n",
      " [ 40.   0.  12.  49.  15.   5.   0.  58.   3.   0.]\n",
      " [  1.   2.   0.   0.   0.  64.  84.  18.   6.   2.]\n",
      " [  0. 100.   4.  12.   0.   1.   2.  60.   4.   0.]\n",
      " [  0.   0.   1.   2. 161.   0.   0.   2.   5.  10.]\n",
      " [  0.   9. 109.  54.   6.   0.   0.   1.   0.   3.]\n",
      " [ 21.   9.   0.   0.  89.   2.   0.   0.   0.  60.]\n",
      " [  0.   0.   3.   0.   0.   2.   0.  89.  85.   0.]\n",
      " [  9.  19.  31.  45.   5.  17.   2.  27.   4.  15.]\n",
      " [  0.  56.   8.  98.   0.   0.   1.   4.  12.   1.]]\n",
      "A large majority of a single prediction number for the target value shows relative 'accuracy'\n",
      "\n",
      "Loss is shows for every 2nd iteration, avg loss per iteration: \n",
      "[1676.68224819143, 1542.6332776850306, 1349.8258208124653, 1671.5959933222036, 1407.561491374513]\n"
     ]
    }
   ],
   "source": [
    "predictions, means, loss_arr = fit(10, 9)\n",
    "\n",
    "print('Target value number (rows) by prediction number(columns):')\n",
    "print(accuracy(predictions,y_train,10))\n",
    "print('A large majority of a single prediction number for the target value shows relative \\'accuracy\\'')\n",
    "\n",
    "k_loss(predictions, means)\n",
    "print('\\nLoss is shows for every 2nd iteration, avg loss per iteration: \\n' + str(loss_arr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
